{
    "docs": [
        {
            "location": "/",
            "text": "GNU Wget \u4f7f\u7528\u7b46\u8a18\n\n\n\u9019\u662f\u4f7f\u7528\u300cGNU \nWget\n\u300d\u7684\u7c21\u55ae\u7d00\u9304\u3002\n\n\n\u74b0\u5883\n\n\n\n\nXubuntu 16.04 64\u4f4d\u5143",
            "title": "\u9996\u9801"
        },
        {
            "location": "/#gnu-wget",
            "text": "\u9019\u662f\u4f7f\u7528\u300cGNU  Wget \u300d\u7684\u7c21\u55ae\u7d00\u9304\u3002",
            "title": "GNU Wget \u4f7f\u7528\u7b46\u8a18"
        },
        {
            "location": "/#_1",
            "text": "Xubuntu 16.04 64\u4f4d\u5143",
            "title": "\u74b0\u5883"
        },
        {
            "location": "/content/reference/manual/",
            "text": "manual\n\n\n\u95b1\u8b80\u6587\u4ef6\n\n\n\n\n$ man 1 \nwget\n\n\n$ info wget\n\n\nGNU wget Manual\n\n\nWikipedia / \nWget\n\n\n\u7dad\u57fa\u767e\u79d1 / \nWget\n\n\nArch Wiki / \nwget",
            "title": "manual"
        },
        {
            "location": "/content/reference/manual/#manual",
            "text": "",
            "title": "manual"
        },
        {
            "location": "/content/reference/manual/#_1",
            "text": "$ man 1  wget  $ info wget  GNU wget Manual  Wikipedia /  Wget  \u7dad\u57fa\u767e\u79d1 /  Wget  Arch Wiki /  wget",
            "title": "\u95b1\u8b80\u6587\u4ef6"
        },
        {
            "location": "/content/deb-package/",
            "text": "deb package\n\n\n\u5957\u4ef6\u9023\u7d50\n\n\n\n\nwget",
            "title": "index"
        },
        {
            "location": "/content/deb-package/#deb-package",
            "text": "",
            "title": "deb package"
        },
        {
            "location": "/content/deb-package/#_1",
            "text": "wget",
            "title": "\u5957\u4ef6\u9023\u7d50"
        },
        {
            "location": "/content/deb-package/wget/",
            "text": "wget \u5957\u4ef6\u63a2\u7d22\n\n\n\u4e0b\u8f09\u5957\u4ef6\n\n\n\u4e0b\u8f09\u300c\nwget\n\u300d\u9019\u500b\u5957\u4ef6\u3002\n\n\n$ apt download wget\n\n\n\n\n\u89e3\u958b\u5957\u4ef6\n\n\n\u89e3\u958b\u300cwget_1.17.1-1ubuntu1_amd64.deb\u300d\n\n\n$ dpkg -x wget_1.17.1-1ubuntu1_amd64.deb wget\n\n\n\n\n\u89c0\u770b\u8cc7\u6599\u593e\u7d50\u69cb\n\n\n\u57f7\u884c\n\n\n$ tree wget\n\n\n\n\n\u986f\u793a\n\n\nwget\n\u251c\u2500\u2500 etc\n\u2502\u00a0\u00a0 \u2514\u2500\u2500 wgetrc\n\u2514\u2500\u2500 usr\n    \u251c\u2500\u2500 bin\n    \u2502\u00a0\u00a0 \u2514\u2500\u2500 wget\n    \u2514\u2500\u2500 share\n        \u251c\u2500\u2500 doc\n        \u2502\u00a0\u00a0 \u2514\u2500\u2500 wget\n        \u2502\u00a0\u00a0     \u251c\u2500\u2500 AUTHORS\n        \u2502\u00a0\u00a0     \u251c\u2500\u2500 changelog.Debian.gz\n        \u2502\u00a0\u00a0     \u251c\u2500\u2500 copyright\n        \u2502\u00a0\u00a0     \u251c\u2500\u2500 MAILING-LIST\n        \u2502\u00a0\u00a0     \u251c\u2500\u2500 NEWS.gz\n        \u2502\u00a0\u00a0     \u2514\u2500\u2500 README\n        \u251c\u2500\u2500 info\n        \u2502\u00a0\u00a0 \u2514\u2500\u2500 wget.info.gz\n        \u2514\u2500\u2500 man\n            \u2514\u2500\u2500 man1\n                \u2514\u2500\u2500 wget.1.gz\n\n9 directories, 10 files\n\n\n\n\n\u82e5\u6709\u5b89\u88dd\u9019\u500b\u5957\u4ef6\u7684\u8a71\uff0c\u53ef\u57f7\u884c\n\n\n$ dpkg -L wget\n\n\n\n\n\u986f\u793a\n\n\n/.\n/etc\n/etc/wgetrc\n/usr\n/usr/share\n/usr/share/doc\n/usr/share/doc/wget\n/usr/share/doc/wget/AUTHORS\n/usr/share/doc/wget/NEWS.gz\n/usr/share/doc/wget/copyright\n/usr/share/doc/wget/README\n/usr/share/doc/wget/changelog.Debian.gz\n/usr/share/doc/wget/MAILING-LIST\n/usr/share/man\n/usr/share/man/man1\n/usr/share/man/man1/wget.1.gz\n/usr/share/info\n/usr/share/info/wget.info.gz\n/usr/bin\n/usr/bin/wget\n\n\n\n\nmanpage\n\n\n\u57f7\u884c\n\n\n$ dpkg -L wget | grep '/man/man.*/'\n\n\n\n\n\u986f\u793a\n\n\n/usr/share/man/man1/wget.1.gz\n\n\n\n\n\n\n$ man 1 \nwget\n\n\n\n\ninfo\n\n\n\u57f7\u884c\n\n\n$ info wget\n\n\n\n\n\u4e0b\u8f09 Source Package\n\n\n\u57f7\u884c\n\n\n$ apt source wget\n\n\n\n\n\u6703\u4e0b\u8f09\u300c\nwget\n\u300d\u9019\u500b\u300cSource Package\u300d\n\n\n\u5957\u4ef6\u8cc7\u8a0a\n\n\n\u7db2\u5740: \nhttp://packages.ubuntu.com/xenial/wget\n\n\n\u57f7\u884c\n\n\n$ apt show wget\n\n\n\n\n\u986f\u793a\n\n\nPackage: wget\nVersion: 1.17.1-1ubuntu1\nPriority: standard\nSection: web\nOrigin: Ubuntu\nMaintainer: Ubuntu Developers \nubuntu-devel-discuss@lists.ubuntu.com\n\nOriginal-Maintainer: No\u00ebl K\u00f6the \nnoel@debian.org\n\nBugs: https://bugs.launchpad.net/ubuntu/+filebug\nInstalled-Size: 897 kB\nDepends: libc6 (\n= 2.17), libidn11 (\n= 1.13), libpcre3, libssl1.0.0 (\n= 1.0.1), libuuid1 (\n= 2.16), zlib1g (\n= 1:1.1.4)\nRecommends: ca-certificates\nConflicts: wget-ssl\nHomepage: https://www.gnu.org/software/wget/\nTask: standard, mythbuntu-backend-slave, mythbuntu-backend-master, ubuntu-touch-core, ubuntu-touch, ubuntu-sdk\nSupported: 5y\nDownload-Size: 297 kB\nAPT-Manual-Installed: yes\nAPT-Sources: http://tw.archive.ubuntu.com/ubuntu xenial/main amd64 Packages\nDescription: retrieves files from the web\n Wget is a network utility to retrieve files from the web\n using HTTP(S) and FTP, the two most widely used internet\n protocols. It works non-interactively, so it will work in\n the background, after having logged off. The program supports\n recursive retrieval of web-authoring pages as well as FTP\n sites -- you can use Wget to make mirrors of archives and\n home pages or to travel the web like a WWW robot.\n .\n Wget works particularly well with slow or unstable connections\n by continuing to retrieve a document until the document is fully\n downloaded. Re-getting files from where it left off works on\n servers (both HTTP and FTP) that support it. Both HTTP and FTP\n retrievals can be time stamped, so Wget can see if the remote\n file has changed since the last retrieval and automatically\n retrieve the new version if it has.\n .\n Wget supports proxy servers; this can lighten the network load,\n speed up retrieval, and provide access behind firewalls.\n\n\n\n\n\u6e90\u78bc\u5957\u4ef6\u8cc7\u8a0a\n\n\n\u7db2\u5740: \nhttp://packages.ubuntu.com/source/xenial/wget\n\n\n\u57f7\u884c\n\n\n$ apt showsrc wget\n\n\n\n\n\u986f\u793a\n\n\nPackage: wget\nBinary: wget, wget-udeb\nVersion: 1.17.1-1ubuntu1\nPriority: standard\nSection: web\nMaintainer: Ubuntu Developers \nubuntu-devel-discuss@lists.ubuntu.com\n\nOriginal-Maintainer: No\u00ebl K\u00f6the \nnoel@debian.org\n\nBuild-Depends: debhelper (\n 9.0.0), gettext, texinfo, autotools-dev, libidn11-dev, uuid-dev, libpcre3-dev, libssl-dev, automake\nArchitecture: any\nStandards-Version: 3.9.6\nFormat: 3.0 (quilt)\nDirectory: pool/main/w/wget\nFiles:\n 9eb0a5b54a97e18e70590721dc712162 1929 wget_1.17.1-1ubuntu1.dsc\n a6a908c9ae0e6a4194c628974cc3f05a 3801442 wget_1.17.1.orig.tar.gz\n d4c2b9e10ec44366d3fd7495edc3ee3d 21844 wget_1.17.1-1ubuntu1.debian.tar.xz\nHomepage: https://www.gnu.org/software/wget/\nPackage-List:\n wget deb web important arch=any\n wget-udeb udeb debian-installer extra arch=any\nChecksums-Sha1:\n 1630d218a8d3f366c83f1f6fcfadb56c297a45ec 1929 wget_1.17.1-1ubuntu1.dsc\n a4b9ca464e0cfb8d57b0d890e3d7df99b486b01a 3801442 wget_1.17.1.orig.tar.gz\n 53cba0c0dd13034383e42f3e57d35e74460de688 21844 wget_1.17.1-1ubuntu1.debian.tar.xz\nChecksums-Sha256:\n 3b383aac4b7e62ee3f17a61e2bdbd741219d4ddca7624df6fb6c463c40d08cea 1929 wget_1.17.1-1ubuntu1.dsc\n 029fbb93bdc1c0c5a7507b6076a6ec2f8d34204a85aa87e5b2f61a9405b290f5 3801442 wget_1.17.1.orig.tar.gz\n 8cfc3934105c3a557af28a72283efec5a4694c724d866ded2af7319082bd4711 21844 wget_1.17.1-1ubuntu1.debian.tar.xz",
            "title": "wget"
        },
        {
            "location": "/content/deb-package/wget/#wget",
            "text": "",
            "title": "wget \u5957\u4ef6\u63a2\u7d22"
        },
        {
            "location": "/content/deb-package/wget/#_1",
            "text": "\u4e0b\u8f09\u300c wget \u300d\u9019\u500b\u5957\u4ef6\u3002  $ apt download wget",
            "title": "\u4e0b\u8f09\u5957\u4ef6"
        },
        {
            "location": "/content/deb-package/wget/#_2",
            "text": "\u89e3\u958b\u300cwget_1.17.1-1ubuntu1_amd64.deb\u300d  $ dpkg -x wget_1.17.1-1ubuntu1_amd64.deb wget",
            "title": "\u89e3\u958b\u5957\u4ef6"
        },
        {
            "location": "/content/deb-package/wget/#_3",
            "text": "\u57f7\u884c  $ tree wget  \u986f\u793a  wget\n\u251c\u2500\u2500 etc\n\u2502\u00a0\u00a0 \u2514\u2500\u2500 wgetrc\n\u2514\u2500\u2500 usr\n    \u251c\u2500\u2500 bin\n    \u2502\u00a0\u00a0 \u2514\u2500\u2500 wget\n    \u2514\u2500\u2500 share\n        \u251c\u2500\u2500 doc\n        \u2502\u00a0\u00a0 \u2514\u2500\u2500 wget\n        \u2502\u00a0\u00a0     \u251c\u2500\u2500 AUTHORS\n        \u2502\u00a0\u00a0     \u251c\u2500\u2500 changelog.Debian.gz\n        \u2502\u00a0\u00a0     \u251c\u2500\u2500 copyright\n        \u2502\u00a0\u00a0     \u251c\u2500\u2500 MAILING-LIST\n        \u2502\u00a0\u00a0     \u251c\u2500\u2500 NEWS.gz\n        \u2502\u00a0\u00a0     \u2514\u2500\u2500 README\n        \u251c\u2500\u2500 info\n        \u2502\u00a0\u00a0 \u2514\u2500\u2500 wget.info.gz\n        \u2514\u2500\u2500 man\n            \u2514\u2500\u2500 man1\n                \u2514\u2500\u2500 wget.1.gz\n\n9 directories, 10 files  \u82e5\u6709\u5b89\u88dd\u9019\u500b\u5957\u4ef6\u7684\u8a71\uff0c\u53ef\u57f7\u884c  $ dpkg -L wget  \u986f\u793a  /.\n/etc\n/etc/wgetrc\n/usr\n/usr/share\n/usr/share/doc\n/usr/share/doc/wget\n/usr/share/doc/wget/AUTHORS\n/usr/share/doc/wget/NEWS.gz\n/usr/share/doc/wget/copyright\n/usr/share/doc/wget/README\n/usr/share/doc/wget/changelog.Debian.gz\n/usr/share/doc/wget/MAILING-LIST\n/usr/share/man\n/usr/share/man/man1\n/usr/share/man/man1/wget.1.gz\n/usr/share/info\n/usr/share/info/wget.info.gz\n/usr/bin\n/usr/bin/wget",
            "title": "\u89c0\u770b\u8cc7\u6599\u593e\u7d50\u69cb"
        },
        {
            "location": "/content/deb-package/wget/#manpage",
            "text": "\u57f7\u884c  $ dpkg -L wget | grep '/man/man.*/'  \u986f\u793a  /usr/share/man/man1/wget.1.gz   $ man 1  wget",
            "title": "manpage"
        },
        {
            "location": "/content/deb-package/wget/#info",
            "text": "\u57f7\u884c  $ info wget",
            "title": "info"
        },
        {
            "location": "/content/deb-package/wget/#source-package",
            "text": "\u57f7\u884c  $ apt source wget  \u6703\u4e0b\u8f09\u300c wget \u300d\u9019\u500b\u300cSource Package\u300d",
            "title": "\u4e0b\u8f09 Source Package"
        },
        {
            "location": "/content/deb-package/wget/#_4",
            "text": "\u7db2\u5740:  http://packages.ubuntu.com/xenial/wget  \u57f7\u884c  $ apt show wget  \u986f\u793a  Package: wget\nVersion: 1.17.1-1ubuntu1\nPriority: standard\nSection: web\nOrigin: Ubuntu\nMaintainer: Ubuntu Developers  ubuntu-devel-discuss@lists.ubuntu.com \nOriginal-Maintainer: No\u00ebl K\u00f6the  noel@debian.org \nBugs: https://bugs.launchpad.net/ubuntu/+filebug\nInstalled-Size: 897 kB\nDepends: libc6 ( = 2.17), libidn11 ( = 1.13), libpcre3, libssl1.0.0 ( = 1.0.1), libuuid1 ( = 2.16), zlib1g ( = 1:1.1.4)\nRecommends: ca-certificates\nConflicts: wget-ssl\nHomepage: https://www.gnu.org/software/wget/\nTask: standard, mythbuntu-backend-slave, mythbuntu-backend-master, ubuntu-touch-core, ubuntu-touch, ubuntu-sdk\nSupported: 5y\nDownload-Size: 297 kB\nAPT-Manual-Installed: yes\nAPT-Sources: http://tw.archive.ubuntu.com/ubuntu xenial/main amd64 Packages\nDescription: retrieves files from the web\n Wget is a network utility to retrieve files from the web\n using HTTP(S) and FTP, the two most widely used internet\n protocols. It works non-interactively, so it will work in\n the background, after having logged off. The program supports\n recursive retrieval of web-authoring pages as well as FTP\n sites -- you can use Wget to make mirrors of archives and\n home pages or to travel the web like a WWW robot.\n .\n Wget works particularly well with slow or unstable connections\n by continuing to retrieve a document until the document is fully\n downloaded. Re-getting files from where it left off works on\n servers (both HTTP and FTP) that support it. Both HTTP and FTP\n retrievals can be time stamped, so Wget can see if the remote\n file has changed since the last retrieval and automatically\n retrieve the new version if it has.\n .\n Wget supports proxy servers; this can lighten the network load,\n speed up retrieval, and provide access behind firewalls.",
            "title": "\u5957\u4ef6\u8cc7\u8a0a"
        },
        {
            "location": "/content/deb-package/wget/#_5",
            "text": "\u7db2\u5740:  http://packages.ubuntu.com/source/xenial/wget  \u57f7\u884c  $ apt showsrc wget  \u986f\u793a  Package: wget\nBinary: wget, wget-udeb\nVersion: 1.17.1-1ubuntu1\nPriority: standard\nSection: web\nMaintainer: Ubuntu Developers  ubuntu-devel-discuss@lists.ubuntu.com \nOriginal-Maintainer: No\u00ebl K\u00f6the  noel@debian.org \nBuild-Depends: debhelper (  9.0.0), gettext, texinfo, autotools-dev, libidn11-dev, uuid-dev, libpcre3-dev, libssl-dev, automake\nArchitecture: any\nStandards-Version: 3.9.6\nFormat: 3.0 (quilt)\nDirectory: pool/main/w/wget\nFiles:\n 9eb0a5b54a97e18e70590721dc712162 1929 wget_1.17.1-1ubuntu1.dsc\n a6a908c9ae0e6a4194c628974cc3f05a 3801442 wget_1.17.1.orig.tar.gz\n d4c2b9e10ec44366d3fd7495edc3ee3d 21844 wget_1.17.1-1ubuntu1.debian.tar.xz\nHomepage: https://www.gnu.org/software/wget/\nPackage-List:\n wget deb web important arch=any\n wget-udeb udeb debian-installer extra arch=any\nChecksums-Sha1:\n 1630d218a8d3f366c83f1f6fcfadb56c297a45ec 1929 wget_1.17.1-1ubuntu1.dsc\n a4b9ca464e0cfb8d57b0d890e3d7df99b486b01a 3801442 wget_1.17.1.orig.tar.gz\n 53cba0c0dd13034383e42f3e57d35e74460de688 21844 wget_1.17.1-1ubuntu1.debian.tar.xz\nChecksums-Sha256:\n 3b383aac4b7e62ee3f17a61e2bdbd741219d4ddca7624df6fb6c463c40d08cea 1929 wget_1.17.1-1ubuntu1.dsc\n 029fbb93bdc1c0c5a7507b6076a6ec2f8d34204a85aa87e5b2f61a9405b290f5 3801442 wget_1.17.1.orig.tar.gz\n 8cfc3934105c3a557af28a72283efec5a4694c724d866ded2af7319082bd4711 21844 wget_1.17.1-1ubuntu1.debian.tar.xz",
            "title": "\u6e90\u78bc\u5957\u4ef6\u8cc7\u8a0a"
        },
        {
            "location": "/content/command/wget/",
            "text": "wget command\n\n\n\u89c0\u770b help\n\n\n\u57f7\u884c\n\n\n$ wget\n\n\n\n\n\u986f\u793a\n\n\nwget: missing URL\nUsage: wget [OPTION]... [URL]...\n\nTry `wget --help' for more options.\n\n\n\n\n\u57f7\u884c\n\n\n$ wget --help\n\n\n\n\n\u6216\u662f\u57f7\u884c\n\n\n$ wget -h\n\n\n\n\n\u986f\u793a\n\n\nGNU Wget 1.17.1, a non-interactive network retriever.\nUsage: wget [OPTION]... [URL]...\n\nMandatory arguments to long options are mandatory for short options too.\n\nStartup:\n  -V,  --version                   display the version of Wget and exit\n  -h,  --help                      print this help\n  -b,  --background                go to background after startup\n  -e,  --execute=COMMAND           execute a `.wgetrc'-style command\n\nLogging and input file:\n  -o,  --output-file=FILE          log messages to FILE\n  -a,  --append-output=FILE        append messages to FILE\n  -d,  --debug                     print lots of debugging information\n  -q,  --quiet                     quiet (no output)\n  -v,  --verbose                   be verbose (this is the default)\n  -nv, --no-verbose                turn off verboseness, without being quiet\n       --report-speed=TYPE         output bandwidth as TYPE.  TYPE can be bits\n  -i,  --input-file=FILE           download URLs found in local or external FILE\n  -F,  --force-html                treat input file as HTML\n  -B,  --base=URL                  resolves HTML input-file links (-i -F)\n                                     relative to URL\n       --config=FILE               specify config file to use\n       --no-config                 do not read any config file\n       --rejected-log=FILE         log reasons for URL rejection to FILE\n\nDownload:\n  -t,  --tries=NUMBER              set number of retries to NUMBER (0 unlimits)\n       --retry-connrefused         retry even if connection is refused\n  -O,  --output-document=FILE      write documents to FILE\n  -nc, --no-clobber                skip downloads that would download to\n                                     existing files (overwriting them)\n  -c,  --continue                  resume getting a partially-downloaded file\n       --start-pos=OFFSET          start downloading from zero-based position OFFSET\n       --progress=TYPE             select progress gauge type\n       --show-progress             display the progress bar in any verbosity mode\n  -N,  --timestamping              don't re-retrieve files unless newer than\n                                     local\n       --no-if-modified-since      don't use conditional if-modified-since get\n                                     requests in timestamping mode\n       --no-use-server-timestamps  don't set the local file's timestamp by\n                                     the one on the server\n  -S,  --server-response           print server response\n       --spider                    don't download anything\n  -T,  --timeout=SECONDS           set all timeout values to SECONDS\n       --dns-timeout=SECS          set the DNS lookup timeout to SECS\n       --connect-timeout=SECS      set the connect timeout to SECS\n       --read-timeout=SECS         set the read timeout to SECS\n  -w,  --wait=SECONDS              wait SECONDS between retrievals\n       --waitretry=SECONDS         wait 1..SECONDS between retries of a retrieval\n       --random-wait               wait from 0.5*WAIT...1.5*WAIT secs between retrievals\n       --no-proxy                  explicitly turn off proxy\n  -Q,  --quota=NUMBER              set retrieval quota to NUMBER\n       --bind-address=ADDRESS      bind to ADDRESS (hostname or IP) on local host\n       --limit-rate=RATE           limit download rate to RATE\n       --no-dns-cache              disable caching DNS lookups\n       --restrict-file-names=OS    restrict chars in file names to ones OS allows\n       --ignore-case               ignore case when matching files/directories\n  -4,  --inet4-only                connect only to IPv4 addresses\n  -6,  --inet6-only                connect only to IPv6 addresses\n       --prefer-family=FAMILY      connect first to addresses of specified family,\n                                     one of IPv6, IPv4, or none\n       --user=USER                 set both ftp and http user to USER\n       --password=PASS             set both ftp and http password to PASS\n       --ask-password              prompt for passwords\n       --no-iri                    turn off IRI support\n       --local-encoding=ENC        use ENC as the local encoding for IRIs\n       --remote-encoding=ENC       use ENC as the default remote encoding\n       --unlink                    remove file before clobber\n\nDirectories:\n  -nd, --no-directories            don't create directories\n  -x,  --force-directories         force creation of directories\n  -nH, --no-host-directories       don't create host directories\n       --protocol-directories      use protocol name in directories\n  -P,  --directory-prefix=PREFIX   save files to PREFIX/..\n       --cut-dirs=NUMBER           ignore NUMBER remote directory components\n\nHTTP options:\n       --http-user=USER            set http user to USER\n       --http-password=PASS        set http password to PASS\n       --no-cache                  disallow server-cached data\n       --default-page=NAME         change the default page name (normally\n                                     this is 'index.html'.)\n  -E,  --adjust-extension          save HTML/CSS documents with proper extensions\n       --ignore-length             ignore 'Content-Length' header field\n       --header=STRING             insert STRING among the headers\n       --max-redirect              maximum redirections allowed per page\n       --proxy-user=USER           set USER as proxy username\n       --proxy-password=PASS       set PASS as proxy password\n       --referer=URL               include 'Referer: URL' header in HTTP request\n       --save-headers              save the HTTP headers to file\n  -U,  --user-agent=AGENT          identify as AGENT instead of Wget/VERSION\n       --no-http-keep-alive        disable HTTP keep-alive (persistent connections)\n       --no-cookies                don't use cookies\n       --load-cookies=FILE         load cookies from FILE before session\n       --save-cookies=FILE         save cookies to FILE after session\n       --keep-session-cookies      load and save session (non-permanent) cookies\n       --post-data=STRING          use the POST method; send STRING as the data\n       --post-file=FILE            use the POST method; send contents of FILE\n       --method=HTTPMethod         use method \nHTTPMethod\n in the request\n       --body-data=STRING          send STRING as data. --method MUST be set\n       --body-file=FILE            send contents of FILE. --method MUST be set\n       --content-disposition       honor the Content-Disposition header when\n                                     choosing local file names (EXPERIMENTAL)\n       --content-on-error          output the received content on server errors\n       --auth-no-challenge         send Basic HTTP authentication information\n                                     without first waiting for the server's\n                                     challenge\n\nHTTPS (SSL/TLS) options:\n       --secure-protocol=PR        choose secure protocol, one of auto, SSLv2,\n                                     SSLv3, TLSv1 and PFS\n       --https-only                only follow secure HTTPS links\n       --no-check-certificate      don't validate the server's certificate\n       --certificate=FILE          client certificate file\n       --certificate-type=TYPE     client certificate type, PEM or DER\n       --private-key=FILE          private key file\n       --private-key-type=TYPE     private key type, PEM or DER\n       --ca-certificate=FILE       file with the bundle of CAs\n       --ca-directory=DIR          directory where hash list of CAs is stored\n       --crl-file=FILE             file with bundle of CRLs\n       --random-file=FILE          file with random data for seeding the SSL PRNG\n       --egd-file=FILE             file naming the EGD socket with random data\n\nHSTS options:\n       --no-hsts                   disable HSTS\n       --hsts-file                 path of HSTS database (will override default)\n\nFTP options:\n       --ftp-user=USER             set ftp user to USER\n       --ftp-password=PASS         set ftp password to PASS\n       --no-remove-listing         don't remove '.listing' files\n       --no-glob                   turn off FTP file name globbing\n       --no-passive-ftp            disable the \npassive\n transfer mode\n       --preserve-permissions      preserve remote file permissions\n       --retr-symlinks             when recursing, get linked-to files (not dir)\n\nFTPS options:\n       --ftps-implicit                 use implicit FTPS (default port is 990)\n       --ftps-resume-ssl               resume the SSL/TLS session started in the control connection when\n                                         opening a data connection\n       --ftps-clear-data-connection    cipher the control channel only; all the data will be in plaintext\n       --ftps-fallback-to-ftp          fall back to FTP if FTPS is not supported in the target server\nWARC options:\n       --warc-file=FILENAME        save request/response data to a .warc.gz file\n       --warc-header=STRING        insert STRING into the warcinfo record\n       --warc-max-size=NUMBER      set maximum size of WARC files to NUMBER\n       --warc-cdx                  write CDX index files\n       --warc-dedup=FILENAME       do not store records listed in this CDX file\n       --no-warc-compression       do not compress WARC files with GZIP\n       --no-warc-digests           do not calculate SHA1 digests\n       --no-warc-keep-log          do not store the log file in a WARC record\n       --warc-tempdir=DIRECTORY    location for temporary files created by the\n                                     WARC writer\n\nRecursive download:\n  -r,  --recursive                 specify recursive download\n  -l,  --level=NUMBER              maximum recursion depth (inf or 0 for infinite)\n       --delete-after              delete files locally after downloading them\n  -k,  --convert-links             make links in downloaded HTML or CSS point to\n                                     local files\n       --convert-file-only         convert the file part of the URLs only (usually known as the basename)\n       --backups=N                 before writing file X, rotate up to N backup files\n  -K,  --backup-converted          before converting file X, back up as X.orig\n  -m,  --mirror                    shortcut for -N -r -l inf --no-remove-listing\n  -p,  --page-requisites           get all images, etc. needed to display HTML page\n       --strict-comments           turn on strict (SGML) handling of HTML comments\n\nRecursive accept/reject:\n  -A,  --accept=LIST               comma-separated list of accepted extensions\n  -R,  --reject=LIST               comma-separated list of rejected extensions\n       --accept-regex=REGEX        regex matching accepted URLs\n       --reject-regex=REGEX        regex matching rejected URLs\n       --regex-type=TYPE           regex type (posix|pcre)\n  -D,  --domains=LIST              comma-separated list of accepted domains\n       --exclude-domains=LIST      comma-separated list of rejected domains\n       --follow-ftp                follow FTP links from HTML documents\n       --follow-tags=LIST          comma-separated list of followed HTML tags\n       --ignore-tags=LIST          comma-separated list of ignored HTML tags\n  -H,  --span-hosts                go to foreign hosts when recursive\n  -L,  --relative                  follow relative links only\n  -I,  --include-directories=LIST  list of allowed directories\n       --trust-server-names        use the name specified by the redirection\n                                     URL's last component\n  -X,  --exclude-directories=LIST  list of excluded directories\n  -np, --no-parent                 don't ascend to the parent directory\n\nMail bug reports and suggestions to \nbug-wget@gnu.org\n\n\n\n\n\u89c0\u770b Version\n\n\n\u57f7\u884c\n\n\n$ wget --version\n\n\n\n\n\u6216\u662f\u57f7\u884c\n\n\n$ wget -V\n\n\n\n\n\u986f\u793a\n\n\nGNU Wget 1.17.1 built on linux-gnu.\n\n+digest -gpgme +https +ipv6 +iri +large-file -metalink +nls +ntlm\n+opie -psl +ssl/openssl\n\nWgetrc:\n    /etc/wgetrc (system)\nLocale:\n    /usr/share/locale\nCompile:\n    gcc -DHAVE_CONFIG_H -DSYSTEM_WGETRC=\n/etc/wgetrc\n\n    -DLOCALEDIR=\n/usr/share/locale\n -I. -I../../src -I../lib\n    -I../../lib -D_FORTIFY_SOURCE=2 -I/usr/include -DHAVE_LIBSSL\n    -DNDEBUG -g -O2 -fPIE -fstack-protector-strong -Wformat\n    -Werror=format-security -DNO_SSLv2 -D_FILE_OFFSET_BITS=64 -g -Wall\nLink:\n    gcc -DHAVE_LIBSSL -DNDEBUG -g -O2 -fPIE -fstack-protector-strong\n    -Wformat -Werror=format-security -DNO_SSLv2 -D_FILE_OFFSET_BITS=64\n    -g -Wall -Wl,-Bsymbolic-functions -fPIE -pie -Wl,-z,relro\n    -Wl,-z,now -L/usr/lib -lpcre -luuid -lssl -lcrypto -lz -lidn\n    ftp-opie.o openssl.o http-ntlm.o ../lib/libgnu.a\n\nCopyright (C) 2015 Free Software Foundation, Inc.\nLicense GPLv3+: GNU GPL version 3 or later\n\nhttp://www.gnu.org/licenses/gpl.html\n.\nThis is free software: you are free to change and redistribute it.\nThere is NO WARRANTY, to the extent permitted by law.\n\nOriginally written by Hrvoje Niksic \nhniksic@xemacs.org\n.\nPlease send bug reports and questions to \nbug-wget@gnu.org\n.\n\n\n\n\n\u57f7\u884c\u6307\u4ee4\n\n\n$ wget https://www.gnu.org/software/wget/\n\n\n\n\n\u89c0\u770b manpage\n\n\n\u57f7\u884c\n\n\n$ man wget\n\n\n\n\n\u6703\u770b\u5230\n\u8aaa\u660e\n\n\n\u67e5\u8a62 wget \u653e\u5728\u90a3\u500b\u4f4d\u7f6e\n\n\n\u57f7\u884c\n\n\n$ whereis wget\n\n\n\n\n\u986f\u793a\n\n\nwget: /usr/bin/wget /usr/share/man/man1/wget.1.gz /usr/share/info/wget.info.gz\n\n\n\n\n\u67e5\u8a62 wget \u5c6c\u65bc\u90a3\u500b\u5957\u4ef6\n\n\n\u57f7\u884c\n\n\n$ dpkg -S /usr/bin/wget\n\n\n\n\n\u986f\u793a\n\n\nwget: /usr/bin/wget\n\n\n\n\n\u8868\u793a\u300c/usr/bin/wget\u300d\u662f\u5c6c\u65bc\u300c\nwget\n\u300d\u9019\u500b\u5957\u4ef6\u3002",
            "title": "wget"
        },
        {
            "location": "/content/command/wget/#wget-command",
            "text": "",
            "title": "wget command"
        },
        {
            "location": "/content/command/wget/#help",
            "text": "\u57f7\u884c  $ wget  \u986f\u793a  wget: missing URL\nUsage: wget [OPTION]... [URL]...\n\nTry `wget --help' for more options.  \u57f7\u884c  $ wget --help  \u6216\u662f\u57f7\u884c  $ wget -h  \u986f\u793a  GNU Wget 1.17.1, a non-interactive network retriever.\nUsage: wget [OPTION]... [URL]...\n\nMandatory arguments to long options are mandatory for short options too.\n\nStartup:\n  -V,  --version                   display the version of Wget and exit\n  -h,  --help                      print this help\n  -b,  --background                go to background after startup\n  -e,  --execute=COMMAND           execute a `.wgetrc'-style command\n\nLogging and input file:\n  -o,  --output-file=FILE          log messages to FILE\n  -a,  --append-output=FILE        append messages to FILE\n  -d,  --debug                     print lots of debugging information\n  -q,  --quiet                     quiet (no output)\n  -v,  --verbose                   be verbose (this is the default)\n  -nv, --no-verbose                turn off verboseness, without being quiet\n       --report-speed=TYPE         output bandwidth as TYPE.  TYPE can be bits\n  -i,  --input-file=FILE           download URLs found in local or external FILE\n  -F,  --force-html                treat input file as HTML\n  -B,  --base=URL                  resolves HTML input-file links (-i -F)\n                                     relative to URL\n       --config=FILE               specify config file to use\n       --no-config                 do not read any config file\n       --rejected-log=FILE         log reasons for URL rejection to FILE\n\nDownload:\n  -t,  --tries=NUMBER              set number of retries to NUMBER (0 unlimits)\n       --retry-connrefused         retry even if connection is refused\n  -O,  --output-document=FILE      write documents to FILE\n  -nc, --no-clobber                skip downloads that would download to\n                                     existing files (overwriting them)\n  -c,  --continue                  resume getting a partially-downloaded file\n       --start-pos=OFFSET          start downloading from zero-based position OFFSET\n       --progress=TYPE             select progress gauge type\n       --show-progress             display the progress bar in any verbosity mode\n  -N,  --timestamping              don't re-retrieve files unless newer than\n                                     local\n       --no-if-modified-since      don't use conditional if-modified-since get\n                                     requests in timestamping mode\n       --no-use-server-timestamps  don't set the local file's timestamp by\n                                     the one on the server\n  -S,  --server-response           print server response\n       --spider                    don't download anything\n  -T,  --timeout=SECONDS           set all timeout values to SECONDS\n       --dns-timeout=SECS          set the DNS lookup timeout to SECS\n       --connect-timeout=SECS      set the connect timeout to SECS\n       --read-timeout=SECS         set the read timeout to SECS\n  -w,  --wait=SECONDS              wait SECONDS between retrievals\n       --waitretry=SECONDS         wait 1..SECONDS between retries of a retrieval\n       --random-wait               wait from 0.5*WAIT...1.5*WAIT secs between retrievals\n       --no-proxy                  explicitly turn off proxy\n  -Q,  --quota=NUMBER              set retrieval quota to NUMBER\n       --bind-address=ADDRESS      bind to ADDRESS (hostname or IP) on local host\n       --limit-rate=RATE           limit download rate to RATE\n       --no-dns-cache              disable caching DNS lookups\n       --restrict-file-names=OS    restrict chars in file names to ones OS allows\n       --ignore-case               ignore case when matching files/directories\n  -4,  --inet4-only                connect only to IPv4 addresses\n  -6,  --inet6-only                connect only to IPv6 addresses\n       --prefer-family=FAMILY      connect first to addresses of specified family,\n                                     one of IPv6, IPv4, or none\n       --user=USER                 set both ftp and http user to USER\n       --password=PASS             set both ftp and http password to PASS\n       --ask-password              prompt for passwords\n       --no-iri                    turn off IRI support\n       --local-encoding=ENC        use ENC as the local encoding for IRIs\n       --remote-encoding=ENC       use ENC as the default remote encoding\n       --unlink                    remove file before clobber\n\nDirectories:\n  -nd, --no-directories            don't create directories\n  -x,  --force-directories         force creation of directories\n  -nH, --no-host-directories       don't create host directories\n       --protocol-directories      use protocol name in directories\n  -P,  --directory-prefix=PREFIX   save files to PREFIX/..\n       --cut-dirs=NUMBER           ignore NUMBER remote directory components\n\nHTTP options:\n       --http-user=USER            set http user to USER\n       --http-password=PASS        set http password to PASS\n       --no-cache                  disallow server-cached data\n       --default-page=NAME         change the default page name (normally\n                                     this is 'index.html'.)\n  -E,  --adjust-extension          save HTML/CSS documents with proper extensions\n       --ignore-length             ignore 'Content-Length' header field\n       --header=STRING             insert STRING among the headers\n       --max-redirect              maximum redirections allowed per page\n       --proxy-user=USER           set USER as proxy username\n       --proxy-password=PASS       set PASS as proxy password\n       --referer=URL               include 'Referer: URL' header in HTTP request\n       --save-headers              save the HTTP headers to file\n  -U,  --user-agent=AGENT          identify as AGENT instead of Wget/VERSION\n       --no-http-keep-alive        disable HTTP keep-alive (persistent connections)\n       --no-cookies                don't use cookies\n       --load-cookies=FILE         load cookies from FILE before session\n       --save-cookies=FILE         save cookies to FILE after session\n       --keep-session-cookies      load and save session (non-permanent) cookies\n       --post-data=STRING          use the POST method; send STRING as the data\n       --post-file=FILE            use the POST method; send contents of FILE\n       --method=HTTPMethod         use method  HTTPMethod  in the request\n       --body-data=STRING          send STRING as data. --method MUST be set\n       --body-file=FILE            send contents of FILE. --method MUST be set\n       --content-disposition       honor the Content-Disposition header when\n                                     choosing local file names (EXPERIMENTAL)\n       --content-on-error          output the received content on server errors\n       --auth-no-challenge         send Basic HTTP authentication information\n                                     without first waiting for the server's\n                                     challenge\n\nHTTPS (SSL/TLS) options:\n       --secure-protocol=PR        choose secure protocol, one of auto, SSLv2,\n                                     SSLv3, TLSv1 and PFS\n       --https-only                only follow secure HTTPS links\n       --no-check-certificate      don't validate the server's certificate\n       --certificate=FILE          client certificate file\n       --certificate-type=TYPE     client certificate type, PEM or DER\n       --private-key=FILE          private key file\n       --private-key-type=TYPE     private key type, PEM or DER\n       --ca-certificate=FILE       file with the bundle of CAs\n       --ca-directory=DIR          directory where hash list of CAs is stored\n       --crl-file=FILE             file with bundle of CRLs\n       --random-file=FILE          file with random data for seeding the SSL PRNG\n       --egd-file=FILE             file naming the EGD socket with random data\n\nHSTS options:\n       --no-hsts                   disable HSTS\n       --hsts-file                 path of HSTS database (will override default)\n\nFTP options:\n       --ftp-user=USER             set ftp user to USER\n       --ftp-password=PASS         set ftp password to PASS\n       --no-remove-listing         don't remove '.listing' files\n       --no-glob                   turn off FTP file name globbing\n       --no-passive-ftp            disable the  passive  transfer mode\n       --preserve-permissions      preserve remote file permissions\n       --retr-symlinks             when recursing, get linked-to files (not dir)\n\nFTPS options:\n       --ftps-implicit                 use implicit FTPS (default port is 990)\n       --ftps-resume-ssl               resume the SSL/TLS session started in the control connection when\n                                         opening a data connection\n       --ftps-clear-data-connection    cipher the control channel only; all the data will be in plaintext\n       --ftps-fallback-to-ftp          fall back to FTP if FTPS is not supported in the target server\nWARC options:\n       --warc-file=FILENAME        save request/response data to a .warc.gz file\n       --warc-header=STRING        insert STRING into the warcinfo record\n       --warc-max-size=NUMBER      set maximum size of WARC files to NUMBER\n       --warc-cdx                  write CDX index files\n       --warc-dedup=FILENAME       do not store records listed in this CDX file\n       --no-warc-compression       do not compress WARC files with GZIP\n       --no-warc-digests           do not calculate SHA1 digests\n       --no-warc-keep-log          do not store the log file in a WARC record\n       --warc-tempdir=DIRECTORY    location for temporary files created by the\n                                     WARC writer\n\nRecursive download:\n  -r,  --recursive                 specify recursive download\n  -l,  --level=NUMBER              maximum recursion depth (inf or 0 for infinite)\n       --delete-after              delete files locally after downloading them\n  -k,  --convert-links             make links in downloaded HTML or CSS point to\n                                     local files\n       --convert-file-only         convert the file part of the URLs only (usually known as the basename)\n       --backups=N                 before writing file X, rotate up to N backup files\n  -K,  --backup-converted          before converting file X, back up as X.orig\n  -m,  --mirror                    shortcut for -N -r -l inf --no-remove-listing\n  -p,  --page-requisites           get all images, etc. needed to display HTML page\n       --strict-comments           turn on strict (SGML) handling of HTML comments\n\nRecursive accept/reject:\n  -A,  --accept=LIST               comma-separated list of accepted extensions\n  -R,  --reject=LIST               comma-separated list of rejected extensions\n       --accept-regex=REGEX        regex matching accepted URLs\n       --reject-regex=REGEX        regex matching rejected URLs\n       --regex-type=TYPE           regex type (posix|pcre)\n  -D,  --domains=LIST              comma-separated list of accepted domains\n       --exclude-domains=LIST      comma-separated list of rejected domains\n       --follow-ftp                follow FTP links from HTML documents\n       --follow-tags=LIST          comma-separated list of followed HTML tags\n       --ignore-tags=LIST          comma-separated list of ignored HTML tags\n  -H,  --span-hosts                go to foreign hosts when recursive\n  -L,  --relative                  follow relative links only\n  -I,  --include-directories=LIST  list of allowed directories\n       --trust-server-names        use the name specified by the redirection\n                                     URL's last component\n  -X,  --exclude-directories=LIST  list of excluded directories\n  -np, --no-parent                 don't ascend to the parent directory\n\nMail bug reports and suggestions to  bug-wget@gnu.org",
            "title": "\u89c0\u770b help"
        },
        {
            "location": "/content/command/wget/#version",
            "text": "\u57f7\u884c  $ wget --version  \u6216\u662f\u57f7\u884c  $ wget -V  \u986f\u793a  GNU Wget 1.17.1 built on linux-gnu.\n\n+digest -gpgme +https +ipv6 +iri +large-file -metalink +nls +ntlm\n+opie -psl +ssl/openssl\n\nWgetrc:\n    /etc/wgetrc (system)\nLocale:\n    /usr/share/locale\nCompile:\n    gcc -DHAVE_CONFIG_H -DSYSTEM_WGETRC= /etc/wgetrc \n    -DLOCALEDIR= /usr/share/locale  -I. -I../../src -I../lib\n    -I../../lib -D_FORTIFY_SOURCE=2 -I/usr/include -DHAVE_LIBSSL\n    -DNDEBUG -g -O2 -fPIE -fstack-protector-strong -Wformat\n    -Werror=format-security -DNO_SSLv2 -D_FILE_OFFSET_BITS=64 -g -Wall\nLink:\n    gcc -DHAVE_LIBSSL -DNDEBUG -g -O2 -fPIE -fstack-protector-strong\n    -Wformat -Werror=format-security -DNO_SSLv2 -D_FILE_OFFSET_BITS=64\n    -g -Wall -Wl,-Bsymbolic-functions -fPIE -pie -Wl,-z,relro\n    -Wl,-z,now -L/usr/lib -lpcre -luuid -lssl -lcrypto -lz -lidn\n    ftp-opie.o openssl.o http-ntlm.o ../lib/libgnu.a\n\nCopyright (C) 2015 Free Software Foundation, Inc.\nLicense GPLv3+: GNU GPL version 3 or later http://www.gnu.org/licenses/gpl.html .\nThis is free software: you are free to change and redistribute it.\nThere is NO WARRANTY, to the extent permitted by law.\n\nOriginally written by Hrvoje Niksic  hniksic@xemacs.org .\nPlease send bug reports and questions to  bug-wget@gnu.org .",
            "title": "\u89c0\u770b Version"
        },
        {
            "location": "/content/command/wget/#_1",
            "text": "$ wget https://www.gnu.org/software/wget/",
            "title": "\u57f7\u884c\u6307\u4ee4"
        },
        {
            "location": "/content/command/wget/#manpage",
            "text": "\u57f7\u884c  $ man wget  \u6703\u770b\u5230 \u8aaa\u660e",
            "title": "\u89c0\u770b manpage"
        },
        {
            "location": "/content/command/wget/#wget",
            "text": "\u57f7\u884c  $ whereis wget  \u986f\u793a  wget: /usr/bin/wget /usr/share/man/man1/wget.1.gz /usr/share/info/wget.info.gz",
            "title": "\u67e5\u8a62 wget \u653e\u5728\u90a3\u500b\u4f4d\u7f6e"
        },
        {
            "location": "/content/command/wget/#wget_1",
            "text": "\u57f7\u884c  $ dpkg -S /usr/bin/wget  \u986f\u793a  wget: /usr/bin/wget  \u8868\u793a\u300c/usr/bin/wget\u300d\u662f\u5c6c\u65bc\u300c wget \u300d\u9019\u500b\u5957\u4ef6\u3002",
            "title": "\u67e5\u8a62 wget \u5c6c\u65bc\u90a3\u500b\u5957\u4ef6"
        },
        {
            "location": "/content/usage/basic/",
            "text": "\u57fa\u672c\u7528\u6cd5\u7bc4\u4f8b\n\n\n\u57fa\u672c\u7528\u6cd5\n\n\n\u57f7\u884c\n\n\n$ wget https://www.gnu.org/software/wget/\n\n\n\n\n\u66f4\u540d\n\n\n\u57f7\u884c\n\n\n$ wget https://www.gnu.org/software/wget/ -O test.html\n\n\n\n\n\u652f\u63f4\u7e8c\u50b3\n\n\n\u57f7\u884c\n\n\n$ wget -c https://dl.google.com/linux/direct/google-chrome-stable_current_amd64.deb\n\n\n\n\n\u5217\u8868\u4e0b\u8f09\n\n\n\u7522\u751f\u4e00\u500b\u300clist.txt\u300d\uff0c\u5167\u5bb9\u662f\u653e\u7f6e\u8981\u4e0b\u8f09\u7684\u6a94\u6848\u5217\u8868\u3002\n\n\n\u57f7\u884c\n\n\ncat \n list.txt \nEOF\nhttp://releases.ubuntu.com/16.04/ubuntu-16.04-desktop-amd64.iso\nhttp://releases.ubuntu.com/16.04/ubuntu-16.04-server-amd64.iso\nhttp://cdimage.ubuntu.com/xubuntu/releases/16.04/release/xubuntu-16.04-desktop-amd64.iso\nhttp://cdimage.ubuntu.com/lubuntu/releases/16.04/release/lubuntu-16.04-desktop-amd64.iso\nhttp://cdimage.ubuntu.com/kubuntu/releases/16.04/release/kubuntu-16.04-desktop-amd64.iso\nhttp://cdimage.ubuntu.com/ubuntu-gnome/releases/16.04/release/ubuntu-gnome-16.04-desktop-amd64.iso\nhttp://cdimage.ubuntu.com/ubuntu-mate/releases/16.04/release/ubuntu-mate-16.04-desktop-amd64.iso\nEOF\n\n\n\n\n\u57f7\u884c\n\n\n$ wget -i list.txt\n\n\n\n\n\u57fa\u672c\u780d\u7ad9\n\n\n\u57f7\u884c\n\n\n$ wget -c -k -r http://localhost\n\n\n\n\n\u4e3b\u8981\u662f\u300c-r\u300d\u9019\u500b\u53c3\u6578\u300c--recursive\u300d\uff0c\u300c-k\u300d\u5247\u662f\u300c--convert-links\u300d\uff0c\u300c-c\u300d\u5247\u662f\u300c--continue\u300d\u3002\n\u66f4\u591a\u8acb\u53c3\u8003\u300cman \nwget\n\u300d",
            "title": "basic"
        },
        {
            "location": "/content/usage/basic/#_1",
            "text": "",
            "title": "\u57fa\u672c\u7528\u6cd5\u7bc4\u4f8b"
        },
        {
            "location": "/content/usage/basic/#_2",
            "text": "\u57f7\u884c  $ wget https://www.gnu.org/software/wget/",
            "title": "\u57fa\u672c\u7528\u6cd5"
        },
        {
            "location": "/content/usage/basic/#_3",
            "text": "\u57f7\u884c  $ wget https://www.gnu.org/software/wget/ -O test.html",
            "title": "\u66f4\u540d"
        },
        {
            "location": "/content/usage/basic/#_4",
            "text": "\u57f7\u884c  $ wget -c https://dl.google.com/linux/direct/google-chrome-stable_current_amd64.deb",
            "title": "\u652f\u63f4\u7e8c\u50b3"
        },
        {
            "location": "/content/usage/basic/#_5",
            "text": "\u7522\u751f\u4e00\u500b\u300clist.txt\u300d\uff0c\u5167\u5bb9\u662f\u653e\u7f6e\u8981\u4e0b\u8f09\u7684\u6a94\u6848\u5217\u8868\u3002  \u57f7\u884c  cat   list.txt  EOF\nhttp://releases.ubuntu.com/16.04/ubuntu-16.04-desktop-amd64.iso\nhttp://releases.ubuntu.com/16.04/ubuntu-16.04-server-amd64.iso\nhttp://cdimage.ubuntu.com/xubuntu/releases/16.04/release/xubuntu-16.04-desktop-amd64.iso\nhttp://cdimage.ubuntu.com/lubuntu/releases/16.04/release/lubuntu-16.04-desktop-amd64.iso\nhttp://cdimage.ubuntu.com/kubuntu/releases/16.04/release/kubuntu-16.04-desktop-amd64.iso\nhttp://cdimage.ubuntu.com/ubuntu-gnome/releases/16.04/release/ubuntu-gnome-16.04-desktop-amd64.iso\nhttp://cdimage.ubuntu.com/ubuntu-mate/releases/16.04/release/ubuntu-mate-16.04-desktop-amd64.iso\nEOF  \u57f7\u884c  $ wget -i list.txt",
            "title": "\u5217\u8868\u4e0b\u8f09"
        },
        {
            "location": "/content/usage/basic/#_6",
            "text": "\u57f7\u884c  $ wget -c -k -r http://localhost  \u4e3b\u8981\u662f\u300c-r\u300d\u9019\u500b\u53c3\u6578\u300c--recursive\u300d\uff0c\u300c-k\u300d\u5247\u662f\u300c--convert-links\u300d\uff0c\u300c-c\u300d\u5247\u662f\u300c--continue\u300d\u3002\n\u66f4\u591a\u8acb\u53c3\u8003\u300cman  wget \u300d",
            "title": "\u57fa\u672c\u780d\u7ad9"
        },
        {
            "location": "/content/usage/cookie/",
            "text": "cookie\n\n\nmanpage\n\n\n$ man \nwget\n\n\n\u53ef\u4ee5\u627e\u5230\u8ddf\u300ccookie\u300d\u76f8\u95dc\u7684\u4f7f\u7528\u8aaa\u660e\n\n\n--no-cookies\n\n\n--no-cookies\n    Disable the use of cookies.  Cookies are a mechanism for maintaining server-side state.  The server sends\n    the client a cookie using the \nSet-Cookie\n header, and the client responds with the same cookie upon\n    further requests.  Since cookies allow the server owners to keep track of visitors and for sites to\n    exchange this information, some consider them a breach of privacy.  The default is to use cookies; however,\n    storing cookies is not on by default.\n\n\n\n\n--load-cookies file\n\n\n--load-cookies file\n    Load cookies from file before the first HTTP retrieval.  file is a textual file in the format originally\n    used by Netscape's cookies.txt file.\n\n    You will typically use this option when mirroring sites that require that you be logged in to access some\n    or all of their content.  The login process typically works by the web server issuing an HTTP cookie upon\n    receiving and verifying your credentials.  The cookie is then resent by the browser when accessing that\n    part of the site, and so proves your identity.\n\n    Mirroring such a site requires Wget to send the same cookies your browser sends when communicating with the\n    site.  This is achieved by --load-cookies---simply point Wget to the location of the cookies.txt file, and\n    it will send the same cookies your browser would send in the same situation.  Different browsers keep\n    textual cookie files in different locations:\n\n    \nNetscape 4.x.\n\n        The cookies are in ~/.netscape/cookies.txt.\n\n    \nMozilla and Netscape 6.x.\n\n        Mozilla's cookie file is also named cookies.txt, located somewhere under ~/.mozilla, in the directory\n        of your profile.  The full path usually ends up looking somewhat like ~/.mozilla/default/some-weird-\n        string/cookies.txt.\n\n    \nInternet Explorer.\n\n        You can produce a cookie file Wget can use by using the File menu, Import and Export, Export Cookies.\n        This has been tested with Internet Explorer 5; it is not guaranteed to work with earlier versions.\n\n    \nOther browsers.\n\n        If you are using a different browser to create your cookies, --load-cookies will only work if you can\n        locate or produce a cookie file in the Netscape format that Wget expects.\n\n    If you cannot use --load-cookies, there might still be an alternative.  If your browser supports a \ncookie\n    manager\n, you can use it to view the cookies used when accessing the site you're mirroring.  Write down the\n    name and value of the cookie, and manually instruct Wget to send those cookies, bypassing the \nofficial\n\n    cookie support:\n\n            wget --no-cookies --header \nCookie: \nname\n=\nvalue\n\n\n\n\n--save-cookies file\n\n\n--save-cookies file\n    Save cookies to file before exiting.  This will not save cookies that have expired or that have no expiry\n    time (so-called \nsession cookies\n), but also see --keep-session-cookies.\n\n\n\n\n--keep-session-cookies\n\n\n--keep-session-cookies\n    When specified, causes --save-cookies to also save session cookies.  Session cookies are normally not saved\n    because they are meant to be kept in memory and forgotten when you exit the browser.  Saving them is useful\n    on sites that require you to log in or to visit the home page before you can access some pages.  With this\n    option, multiple Wget runs are considered a single browser session as far as the site is concerned.\n\n    Since the cookie file format does not normally carry session cookies, Wget marks them with an expiry\n    timestamp of 0.  Wget's --load-cookies recognizes those as session cookies, but it might confuse other\n    browsers.  Also note that cookies so loaded will be treated as other session cookies, which means that if\n    you want --save-cookies to preserve them again, you must use --keep-session-cookies again.\n\n\n\n\n\u76f8\u95dc\u6848\u4f8b\u8aaa\u660e\n\n\n--post-data=string\n--post-file=file\n    Use POST as the method for all HTTP requests and send the specified data in the request body.  --post-data\n    sends string as data, whereas --post-file sends the contents of file.  Other than that, they work in\n    exactly the same way. In particular, they both expect content of the form \nkey1=value1\nkey2=value2\n, with\n    percent-encoding for special characters; the only difference is that one expects its content as a command-\n    line parameter and the other accepts its content from a file. In particular, --post-file is not for\n    transmitting files as form attachments: those must appear as \nkey=value\n data (with appropriate percent-\n    coding) just like everything else. Wget does not currently support \nmultipart/form-data\n for transmitting\n    POST data; only \napplication/x-www-form-urlencoded\n. Only one of --post-data and --post-file should be\n    specified.\n\n    Please note that wget does not require the content to be of the form \nkey1=value1\nkey2=value2\n, and neither\n    does it test for it. Wget will simply transmit whatever data is provided to it. Most servers however expect\n    the POST data to be in the above format when processing HTML Forms.\n\n    When sending a POST request using the --post-file option, Wget treats the file as a binary file and will\n    send every character in the POST request without stripping trailing newline or formfeed characters. Any\n    other control characters in the text will also be sent as-is in the POST request.\n\n    Please be aware that Wget needs to know the size of the POST data in advance.  Therefore the argument to\n    \n--post-file\n must be a regular file; specifying a FIFO or something like /dev/stdin won't work.  It's not\n    quite clear how to work around this limitation inherent in HTTP/1.0.  Although HTTP/1.1 introduces chunked\n    transfer that doesn't require knowing the request length in advance, a client can't use chunked unless it\n    knows it's talking to an HTTP/1.1 server.  And it can't know that until it receives a response, which in\n    turn requires the request to have been completed -- a chicken-and-egg problem.\n\n    Note: As of version 1.15 if Wget is redirected after the POST request is completed, its behaviour will\n    depend on the response code returned by the server.  In case of a 301 Moved Permanently, 302 Moved\n    Temporarily or 307 Temporary Redirect, Wget will, in accordance with RFC2616, continue to send a POST\n    request.  In case a server wants the client to change the Request method upon redirection, it should send a\n    303 See Other response code.\n\n    This example shows how to log in to a server using POST and then proceed to download the desired pages,\n    presumably only accessible to authorized users:\n\n            # Log in to the server.  This can be done only once.\n            wget --save-cookies cookies.txt \\\n                 --post-data 'user=foo\npassword=bar' \\\n                 http://server.com/auth.php\n\n            # Now grab the page or pages we care about.\n            wget --load-cookies cookies.txt \\\n                 -p http://server.com/interesting/article.php\n\n    If the server is using session cookies to track user authentication, the above will not work because\n    --save-cookies will not save them (and neither will browsers) and the cookies.txt file will be empty.  In\n    that case use --keep-session-cookies along with --save-cookies to force saving of session cookies.\n\n\n\n\n\u7bc4\u4f8b\n\n\n\u524d\u7f6e\u4f5c\u696d\n\n\n\u57f7\u884c\u4e0b\u9762\u7684\u6307\u4ee4\uff0c\u7522\u751f\u4e00\u500b\u6a94\u6848\u300cindex.php\u300d\u3002\n\n\ncat \n index.php \nEOL\n\n?php\n\n    var_dump(\\$_COOKIE);\nEOL\n\n\n\n\n\u5167\u5bb9\u5982\u4e0b\n\n\n?php\n\n    var_dump($_COOKIE);\n\n\n\n\n\u57f7\u884c\u4e0b\u9762\u7684\u6307\u4ee4\uff0c\u7522\u751f\u4e00\u500b\u6a94\u6848\u300ccookie.php\u300d\u3002\n\n\ncat \n cookie.php \nEOL\n\n?php\n\n\\$value = 'something from somewhere';\n\nsetcookie(\nTestCookie\n, \\$value);\nEOL\n\n\n\n\n\u5167\u5bb9\u5982\u4e0b\n\n\n?php\n\n$value = 'something from somewhere';\n\nsetcookie(\nTestCookie\n, $value);\n\n\n\n\n\u57f7\u884c\u4e0b\u9762\u7684\u6307\u4ee4\uff0c\u7522\u751f\u4e00\u500b\u6a94\u6848\u300csession.php\u300d\u3002\n\n\ncat \n session.php \nEOL\n\n?php\n\n    session_start();\nEOL\n\n\n\n\n\u5167\u5bb9\u5982\u4e0b\n\n\n?php\n\n    session_start();\n\n\n\n\n\u555f\u52d5\u300c\u6e2c\u8a66 Web Server\u300d\n\n\n\u57f7\u884c\n\n\n$ php -S localhost:8080\n\n\n\n\n\u5207\u63db\u5230\u6e2c\u8a66\u8def\u5f91\n\n\n\u53e6\u5916\u958b\u4e00\u500b\u300cTerminal\u300d\n\n\n\u57f7\u884c\n\n\nmkdir test -p\ncd test\n\n\n\n\n\u6e2c\u8a66\n\n\n\u57f7\u884c\n\n\n$ wget localhost:8080\n\n\n\n\n\u6703\u7522\u751f\u4e00\u500b\u6a94\u6848\u300cindex.html\u300d\n\n\n\u57f7\u884c\n\n\n$ cat index.html\n\n\n\n\n\u986f\u793a\n\n\narray(0) {                                                                                                                \n}    \n\n\n\n\n\u57f7\u884c\n\n\n$ wget localhost:8080/cookie.php --keep-session-cookies --save-cookies cookie.txt\n\n\n\n\n\u6703\u7522\u751f\u6a94\u6848\u300ccookie.php\u300d\u548c\u300ccookie.txt\u300d\n\n\n\u57f7\u884c\n\n\n$ cat cookie.php\n\n\n\n\n\u6c92\u6709\u4efb\u4f55\u986f\u793a\uff0c\u57f7\u884c\u51fa\u73fe\u4e0b\u4e00\u500b\u63d0\u793a\u5b57\u5143\u3002\n\n\n\u57f7\u884c\n\n\n$ cat cookie.txt\n\n\n\n\n\u986f\u793a\n\n\n# HTTP cookie file.\n# Generated by Wget on 2016-05-12 21:35:21.\n# Edit at your own risk.\n\nlocalhost:8080  FALSE   /       FALSE   0       TestCookie      something+from+somewhere\n\n\n\n\n\u522a\u9664\u300cindex.html\u300d\n\n\n$ rm index.html\n\n\n\n\n\u57f7\u884c\n\n\n$ wget localhost:8080 --load-cookies cookie.txt\n\n\n\n\n\u6703\u7522\u751f\u4e00\u500b\u6a94\u6848\u300cindex.html\u300d\u3002\n\n\n\u57f7\u884c\u4e0b\u9762\u6307\u4ee4\uff0c\u89c0\u770b\u300cindex.html\u300d\u3002\n\n\n$ cat index.html\n\n\n\n\n\u986f\u793a\n\n\narray(1) {\n  [\nTestCookie\n]=\n\n  string(24) \nsomething from somewhere\n\n}\n\n\n\n\n\u57f7\u884c\n\n\n$ wget localhost:8080/session.php --keep-session-cookies --save-cookies cookie.txt\n\n\n\n\n\u6703\u7522\u751f\u6a94\u6848\u300csession.php\u300d\u548c\u300ccookie.txt\u300d\n\n\n\u57f7\u884c\n\n\n$ cat session.php\n\n\n\n\n\u6c92\u6709\u4efb\u4f55\u986f\u793a\uff0c\u57f7\u884c\u51fa\u73fe\u4e0b\u4e00\u500b\u63d0\u793a\u5b57\u5143\u3002\n\n\n\u57f7\u884c\n\n\n$ cat cookie.txt\n\n\n\n\n\u986f\u793a\n\n\n# HTTP cookie file.\n# Generated by Wget on 2016-05-12 21:51:42.\n# Edit at your own risk.\n\nlocalhost:8080  FALSE   /       FALSE   0       PHPSESSID       6u9k9bgolqvcttfun9fftrue85\n\n\n\n\n\u66f4\u591a\u53c3\u8003\n\n\n\n\n\u7dad\u57fa\u767e\u79d1 / https://zh.wikipedia.org/zh-tw/Cookie)\n\n\nWikipedia / \nHTTP_cookie\n\n\nPHP / \nsetcookie\n\n\nPHP / \n$_COOKIE\n\n\nPHP / \nBuilt-in web server",
            "title": "cookie"
        },
        {
            "location": "/content/usage/cookie/#cookie",
            "text": "",
            "title": "cookie"
        },
        {
            "location": "/content/usage/cookie/#manpage",
            "text": "$ man  wget  \u53ef\u4ee5\u627e\u5230\u8ddf\u300ccookie\u300d\u76f8\u95dc\u7684\u4f7f\u7528\u8aaa\u660e",
            "title": "manpage"
        },
        {
            "location": "/content/usage/cookie/#-no-cookies",
            "text": "--no-cookies\n    Disable the use of cookies.  Cookies are a mechanism for maintaining server-side state.  The server sends\n    the client a cookie using the  Set-Cookie  header, and the client responds with the same cookie upon\n    further requests.  Since cookies allow the server owners to keep track of visitors and for sites to\n    exchange this information, some consider them a breach of privacy.  The default is to use cookies; however,\n    storing cookies is not on by default.",
            "title": "--no-cookies"
        },
        {
            "location": "/content/usage/cookie/#-load-cookies-file",
            "text": "--load-cookies file\n    Load cookies from file before the first HTTP retrieval.  file is a textual file in the format originally\n    used by Netscape's cookies.txt file.\n\n    You will typically use this option when mirroring sites that require that you be logged in to access some\n    or all of their content.  The login process typically works by the web server issuing an HTTP cookie upon\n    receiving and verifying your credentials.  The cookie is then resent by the browser when accessing that\n    part of the site, and so proves your identity.\n\n    Mirroring such a site requires Wget to send the same cookies your browser sends when communicating with the\n    site.  This is achieved by --load-cookies---simply point Wget to the location of the cookies.txt file, and\n    it will send the same cookies your browser would send in the same situation.  Different browsers keep\n    textual cookie files in different locations:\n\n     Netscape 4.x. \n        The cookies are in ~/.netscape/cookies.txt.\n\n     Mozilla and Netscape 6.x. \n        Mozilla's cookie file is also named cookies.txt, located somewhere under ~/.mozilla, in the directory\n        of your profile.  The full path usually ends up looking somewhat like ~/.mozilla/default/some-weird-\n        string/cookies.txt.\n\n     Internet Explorer. \n        You can produce a cookie file Wget can use by using the File menu, Import and Export, Export Cookies.\n        This has been tested with Internet Explorer 5; it is not guaranteed to work with earlier versions.\n\n     Other browsers. \n        If you are using a different browser to create your cookies, --load-cookies will only work if you can\n        locate or produce a cookie file in the Netscape format that Wget expects.\n\n    If you cannot use --load-cookies, there might still be an alternative.  If your browser supports a  cookie\n    manager , you can use it to view the cookies used when accessing the site you're mirroring.  Write down the\n    name and value of the cookie, and manually instruct Wget to send those cookies, bypassing the  official \n    cookie support:\n\n            wget --no-cookies --header  Cookie:  name = value",
            "title": "--load-cookies file"
        },
        {
            "location": "/content/usage/cookie/#-save-cookies-file",
            "text": "--save-cookies file\n    Save cookies to file before exiting.  This will not save cookies that have expired or that have no expiry\n    time (so-called  session cookies ), but also see --keep-session-cookies.",
            "title": "--save-cookies file"
        },
        {
            "location": "/content/usage/cookie/#-keep-session-cookies",
            "text": "--keep-session-cookies\n    When specified, causes --save-cookies to also save session cookies.  Session cookies are normally not saved\n    because they are meant to be kept in memory and forgotten when you exit the browser.  Saving them is useful\n    on sites that require you to log in or to visit the home page before you can access some pages.  With this\n    option, multiple Wget runs are considered a single browser session as far as the site is concerned.\n\n    Since the cookie file format does not normally carry session cookies, Wget marks them with an expiry\n    timestamp of 0.  Wget's --load-cookies recognizes those as session cookies, but it might confuse other\n    browsers.  Also note that cookies so loaded will be treated as other session cookies, which means that if\n    you want --save-cookies to preserve them again, you must use --keep-session-cookies again.",
            "title": "--keep-session-cookies"
        },
        {
            "location": "/content/usage/cookie/#_1",
            "text": "--post-data=string\n--post-file=file\n    Use POST as the method for all HTTP requests and send the specified data in the request body.  --post-data\n    sends string as data, whereas --post-file sends the contents of file.  Other than that, they work in\n    exactly the same way. In particular, they both expect content of the form  key1=value1 key2=value2 , with\n    percent-encoding for special characters; the only difference is that one expects its content as a command-\n    line parameter and the other accepts its content from a file. In particular, --post-file is not for\n    transmitting files as form attachments: those must appear as  key=value  data (with appropriate percent-\n    coding) just like everything else. Wget does not currently support  multipart/form-data  for transmitting\n    POST data; only  application/x-www-form-urlencoded . Only one of --post-data and --post-file should be\n    specified.\n\n    Please note that wget does not require the content to be of the form  key1=value1 key2=value2 , and neither\n    does it test for it. Wget will simply transmit whatever data is provided to it. Most servers however expect\n    the POST data to be in the above format when processing HTML Forms.\n\n    When sending a POST request using the --post-file option, Wget treats the file as a binary file and will\n    send every character in the POST request without stripping trailing newline or formfeed characters. Any\n    other control characters in the text will also be sent as-is in the POST request.\n\n    Please be aware that Wget needs to know the size of the POST data in advance.  Therefore the argument to\n     --post-file  must be a regular file; specifying a FIFO or something like /dev/stdin won't work.  It's not\n    quite clear how to work around this limitation inherent in HTTP/1.0.  Although HTTP/1.1 introduces chunked\n    transfer that doesn't require knowing the request length in advance, a client can't use chunked unless it\n    knows it's talking to an HTTP/1.1 server.  And it can't know that until it receives a response, which in\n    turn requires the request to have been completed -- a chicken-and-egg problem.\n\n    Note: As of version 1.15 if Wget is redirected after the POST request is completed, its behaviour will\n    depend on the response code returned by the server.  In case of a 301 Moved Permanently, 302 Moved\n    Temporarily or 307 Temporary Redirect, Wget will, in accordance with RFC2616, continue to send a POST\n    request.  In case a server wants the client to change the Request method upon redirection, it should send a\n    303 See Other response code.\n\n    This example shows how to log in to a server using POST and then proceed to download the desired pages,\n    presumably only accessible to authorized users:\n\n            # Log in to the server.  This can be done only once.\n            wget --save-cookies cookies.txt \\\n                 --post-data 'user=foo password=bar' \\\n                 http://server.com/auth.php\n\n            # Now grab the page or pages we care about.\n            wget --load-cookies cookies.txt \\\n                 -p http://server.com/interesting/article.php\n\n    If the server is using session cookies to track user authentication, the above will not work because\n    --save-cookies will not save them (and neither will browsers) and the cookies.txt file will be empty.  In\n    that case use --keep-session-cookies along with --save-cookies to force saving of session cookies.",
            "title": "\u76f8\u95dc\u6848\u4f8b\u8aaa\u660e"
        },
        {
            "location": "/content/usage/cookie/#_2",
            "text": "",
            "title": "\u7bc4\u4f8b"
        },
        {
            "location": "/content/usage/cookie/#_3",
            "text": "\u57f7\u884c\u4e0b\u9762\u7684\u6307\u4ee4\uff0c\u7522\u751f\u4e00\u500b\u6a94\u6848\u300cindex.php\u300d\u3002  cat   index.php  EOL ?php\n\n    var_dump(\\$_COOKIE);\nEOL  \u5167\u5bb9\u5982\u4e0b  ?php\n\n    var_dump($_COOKIE);  \u57f7\u884c\u4e0b\u9762\u7684\u6307\u4ee4\uff0c\u7522\u751f\u4e00\u500b\u6a94\u6848\u300ccookie.php\u300d\u3002  cat   cookie.php  EOL ?php\n\n\\$value = 'something from somewhere';\n\nsetcookie( TestCookie , \\$value);\nEOL  \u5167\u5bb9\u5982\u4e0b  ?php\n\n$value = 'something from somewhere';\n\nsetcookie( TestCookie , $value);  \u57f7\u884c\u4e0b\u9762\u7684\u6307\u4ee4\uff0c\u7522\u751f\u4e00\u500b\u6a94\u6848\u300csession.php\u300d\u3002  cat   session.php  EOL ?php\n\n    session_start();\nEOL  \u5167\u5bb9\u5982\u4e0b  ?php\n\n    session_start();",
            "title": "\u524d\u7f6e\u4f5c\u696d"
        },
        {
            "location": "/content/usage/cookie/#web-server",
            "text": "\u57f7\u884c  $ php -S localhost:8080",
            "title": "\u555f\u52d5\u300c\u6e2c\u8a66 Web Server\u300d"
        },
        {
            "location": "/content/usage/cookie/#_4",
            "text": "\u53e6\u5916\u958b\u4e00\u500b\u300cTerminal\u300d  \u57f7\u884c  mkdir test -p\ncd test",
            "title": "\u5207\u63db\u5230\u6e2c\u8a66\u8def\u5f91"
        },
        {
            "location": "/content/usage/cookie/#_5",
            "text": "\u57f7\u884c  $ wget localhost:8080  \u6703\u7522\u751f\u4e00\u500b\u6a94\u6848\u300cindex.html\u300d  \u57f7\u884c  $ cat index.html  \u986f\u793a  array(0) {                                                                                                                \n}      \u57f7\u884c  $ wget localhost:8080/cookie.php --keep-session-cookies --save-cookies cookie.txt  \u6703\u7522\u751f\u6a94\u6848\u300ccookie.php\u300d\u548c\u300ccookie.txt\u300d  \u57f7\u884c  $ cat cookie.php  \u6c92\u6709\u4efb\u4f55\u986f\u793a\uff0c\u57f7\u884c\u51fa\u73fe\u4e0b\u4e00\u500b\u63d0\u793a\u5b57\u5143\u3002  \u57f7\u884c  $ cat cookie.txt  \u986f\u793a  # HTTP cookie file.\n# Generated by Wget on 2016-05-12 21:35:21.\n# Edit at your own risk.\n\nlocalhost:8080  FALSE   /       FALSE   0       TestCookie      something+from+somewhere  \u522a\u9664\u300cindex.html\u300d  $ rm index.html  \u57f7\u884c  $ wget localhost:8080 --load-cookies cookie.txt  \u6703\u7522\u751f\u4e00\u500b\u6a94\u6848\u300cindex.html\u300d\u3002  \u57f7\u884c\u4e0b\u9762\u6307\u4ee4\uff0c\u89c0\u770b\u300cindex.html\u300d\u3002  $ cat index.html  \u986f\u793a  array(1) {\n  [ TestCookie ]= \n  string(24)  something from somewhere \n}  \u57f7\u884c  $ wget localhost:8080/session.php --keep-session-cookies --save-cookies cookie.txt  \u6703\u7522\u751f\u6a94\u6848\u300csession.php\u300d\u548c\u300ccookie.txt\u300d  \u57f7\u884c  $ cat session.php  \u6c92\u6709\u4efb\u4f55\u986f\u793a\uff0c\u57f7\u884c\u51fa\u73fe\u4e0b\u4e00\u500b\u63d0\u793a\u5b57\u5143\u3002  \u57f7\u884c  $ cat cookie.txt  \u986f\u793a  # HTTP cookie file.\n# Generated by Wget on 2016-05-12 21:51:42.\n# Edit at your own risk.\n\nlocalhost:8080  FALSE   /       FALSE   0       PHPSESSID       6u9k9bgolqvcttfun9fftrue85",
            "title": "\u6e2c\u8a66"
        },
        {
            "location": "/content/usage/cookie/#_6",
            "text": "\u7dad\u57fa\u767e\u79d1 / https://zh.wikipedia.org/zh-tw/Cookie)  Wikipedia /  HTTP_cookie  PHP /  setcookie  PHP /  $_COOKIE  PHP /  Built-in web server",
            "title": "\u66f4\u591a\u53c3\u8003"
        }
    ]
}